{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26303cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5664d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=latent_dim),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.Dense(28 * 28, activation='tanh'),\n",
    "        layers.Reshape((28, 28, 1))\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c79aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28, 1)),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9c6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_gan(generator, discriminator):\n",
    "    discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), \n",
    "                          loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    discriminator.trainable = False  # Freeze discriminator weights for GAN training\n",
    "    gan = tf.keras.Sequential([generator, discriminator])\n",
    "    gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
    "    return gan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a374cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = x_train / 127.5 - 1.0  # Normalize to [-1, 1]\n",
    "    x_train = np.expand_dims(x_train, axis=-1)\n",
    "    return x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1eb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan, data, epochs, batch_size, latent_dim):\n",
    "    half_batch = batch_size // 2\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train discriminator\n",
    "        idx = np.random.randint(0, data.shape[0], half_batch)\n",
    "        real_imgs = data[idx]\n",
    "        noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "        fake_imgs = generator.predict(noise)\n",
    "        \n",
    "        real_labels = np.ones((half_batch, 1))\n",
    "        fake_labels = np.zeros((half_batch, 1))\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(real_imgs, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        valid_labels = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, valid_labels)\n",
    "        \n",
    "        # Display progress\n",
    "        print(f\"{epoch + 1}/{epochs}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")\n",
    "        \n",
    "        # Save samples periodically\n",
    "        if epoch % 100 == 0:\n",
    "            sample_images(generator, epoch, latent_dim)\n",
    "\n",
    "def sample_images(generator, epoch, latent_dim):\n",
    "    noise = np.random.normal(0, 1, (25, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5  # Rescale to [0, 1]\n",
    "\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(5, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.savefig(f\"generated_images_epoch_{epoch}.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b905c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\slasher\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\slasher\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\slasher\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:71: UserWarning: The model does not have any trainable weights.\n",
      "  warnings.warn(\"The model does not have any trainable weights.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100, Discriminator Loss: 0.6920542120933533, Generator Loss: [array(0.68450713, dtype=float32), array(0.68450713, dtype=float32), array(0.734375, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x0000017490661DA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x00000174925382C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/100, Discriminator Loss: 0.7005037069320679, Generator Loss: [array(0.6988026, dtype=float32), array(0.6988026, dtype=float32), array(0.59375, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "3/100, Discriminator Loss: 0.7185268998146057, Generator Loss: [array(0.71478313, dtype=float32), array(0.71478313, dtype=float32), array(0.5833333, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "4/100, Discriminator Loss: 0.723709225654602, Generator Loss: [array(0.72235096, dtype=float32), array(0.72235096, dtype=float32), array(0.51953125, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "5/100, Discriminator Loss: 0.7187789678573608, Generator Loss: [array(0.7193891, dtype=float32), array(0.7193891, dtype=float32), array(0.490625, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "6/100, Discriminator Loss: 0.7214037179946899, Generator Loss: [array(0.7227053, dtype=float32), array(0.7227053, dtype=float32), array(0.45833334, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "7/100, Discriminator Loss: 0.7265030145645142, Generator Loss: [array(0.7287198, dtype=float32), array(0.7287198, dtype=float32), array(0.43526787, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "8/100, Discriminator Loss: 0.731769323348999, Generator Loss: [array(0.73556423, dtype=float32), array(0.73556423, dtype=float32), array(0.41015625, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "9/100, Discriminator Loss: 0.739930272102356, Generator Loss: [array(0.7445593, dtype=float32), array(0.7445593, dtype=float32), array(0.390625, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "10/100, Discriminator Loss: 0.7499464154243469, Generator Loss: [array(0.75489473, dtype=float32), array(0.75489473, dtype=float32), array(0.371875, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "11/100, Discriminator Loss: 0.7627059817314148, Generator Loss: [array(0.7686966, dtype=float32), array(0.7686966, dtype=float32), array(0.359375, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "12/100, Discriminator Loss: 0.7756626605987549, Generator Loss: [array(0.78265995, dtype=float32), array(0.78265995, dtype=float32), array(0.34765625, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "13/100, Discriminator Loss: 0.7883647084236145, Generator Loss: [array(0.7956811, dtype=float32), array(0.7956811, dtype=float32), array(0.33653846, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "14/100, Discriminator Loss: 0.7995116114616394, Generator Loss: [array(0.8074819, dtype=float32), array(0.8074819, dtype=float32), array(0.3325893, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "15/100, Discriminator Loss: 0.814685583114624, Generator Loss: [array(0.82341385, dtype=float32), array(0.82341385, dtype=float32), array(0.32291666, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "16/100, Discriminator Loss: 0.8300707340240479, Generator Loss: [array(0.8393505, dtype=float32), array(0.8393505, dtype=float32), array(0.31445312, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "17/100, Discriminator Loss: 0.8448504209518433, Generator Loss: [array(0.85396504, dtype=float32), array(0.85396504, dtype=float32), array(0.30790442, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "18/100, Discriminator Loss: 0.8608496189117432, Generator Loss: [array(0.87050843, dtype=float32), array(0.87050843, dtype=float32), array(0.3046875, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "19/100, Discriminator Loss: 0.8771353960037231, Generator Loss: [array(0.8873442, dtype=float32), array(0.8873442, dtype=float32), array(0.2993421, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "20/100, Discriminator Loss: 0.8918999433517456, Generator Loss: [array(0.90052307, dtype=float32), array(0.90052307, dtype=float32), array(0.2984375, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "21/100, Discriminator Loss: 0.9050114154815674, Generator Loss: [array(0.9147695, dtype=float32), array(0.9147695, dtype=float32), array(0.29910713, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "22/100, Discriminator Loss: 0.9200687408447266, Generator Loss: [array(0.9297362, dtype=float32), array(0.9297362, dtype=float32), array(0.29545453, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "23/100, Discriminator Loss: 0.9343466758728027, Generator Loss: [array(0.9443741, dtype=float32), array(0.9443741, dtype=float32), array(0.29347825, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "24/100, Discriminator Loss: 0.9482102990150452, Generator Loss: [array(0.95761055, dtype=float32), array(0.95761055, dtype=float32), array(0.29296875, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "25/100, Discriminator Loss: 0.9637213945388794, Generator Loss: [array(0.9728886, dtype=float32), array(0.9728886, dtype=float32), array(0.288125, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "26/100, Discriminator Loss: 0.9781597852706909, Generator Loss: [array(0.9880055, dtype=float32), array(0.9880055, dtype=float32), array(0.2872596, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "27/100, Discriminator Loss: 0.9931946992874146, Generator Loss: [array(1.0028876, dtype=float32), array(1.0028876, dtype=float32), array(0.2841435, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "28/100, Discriminator Loss: 1.0079138278961182, Generator Loss: [array(1.0176485, dtype=float32), array(1.0176485, dtype=float32), array(0.28125, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "29/100, Discriminator Loss: 1.0214059352874756, Generator Loss: [array(1.0305041, dtype=float32), array(1.0305041, dtype=float32), array(0.2817888, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "30/100, Discriminator Loss: 1.0361405611038208, Generator Loss: [array(1.0461065, dtype=float32), array(1.0461065, dtype=float32), array(0.2796875, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "31/100, Discriminator Loss: 1.0499393939971924, Generator Loss: [array(1.0593437, dtype=float32), array(1.0593437, dtype=float32), array(0.27923387, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "32/100, Discriminator Loss: 1.0631217956542969, Generator Loss: [array(1.0720459, dtype=float32), array(1.0720459, dtype=float32), array(0.27783203, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "33/100, Discriminator Loss: 1.0769538879394531, Generator Loss: [array(1.0868416, dtype=float32), array(1.0868416, dtype=float32), array(0.2755682, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "34/100, Discriminator Loss: 1.0933542251586914, Generator Loss: [array(1.1037141, dtype=float32), array(1.1037141, dtype=float32), array(0.2725184, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "35/100, Discriminator Loss: 1.1085357666015625, Generator Loss: [array(1.1183155, dtype=float32), array(1.1183155, dtype=float32), array(0.2705357, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "36/100, Discriminator Loss: 1.1225826740264893, Generator Loss: [array(1.1320987, dtype=float32), array(1.1320987, dtype=float32), array(0.2690972, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "37/100, Discriminator Loss: 1.1361641883850098, Generator Loss: [array(1.1455972, dtype=float32), array(1.1455972, dtype=float32), array(0.2677365, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "38/100, Discriminator Loss: 1.1497544050216675, Generator Loss: [array(1.1585362, dtype=float32), array(1.1585362, dtype=float32), array(0.26480263, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "39/100, Discriminator Loss: 1.1633732318878174, Generator Loss: [array(1.1728911, dtype=float32), array(1.1728911, dtype=float32), array(0.26241988, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "40/100, Discriminator Loss: 1.1752376556396484, Generator Loss: [array(1.1837183, dtype=float32), array(1.1837183, dtype=float32), array(0.2625, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "41/100, Discriminator Loss: 1.1859482526779175, Generator Loss: [array(1.1948504, dtype=float32), array(1.1948504, dtype=float32), array(0.2637195, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "42/100, Discriminator Loss: 1.1966702938079834, Generator Loss: [array(1.2047501, dtype=float32), array(1.2047501, dtype=float32), array(0.2637649, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "43/100, Discriminator Loss: 1.2068544626235962, Generator Loss: [array(1.2157172, dtype=float32), array(1.2157172, dtype=float32), array(0.26526162, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "44/100, Discriminator Loss: 1.2194904088974, Generator Loss: [array(1.2286056, dtype=float32), array(1.2286056, dtype=float32), array(0.26420453, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "45/100, Discriminator Loss: 1.2308498620986938, Generator Loss: [array(1.2393116, dtype=float32), array(1.2393116, dtype=float32), array(0.265625, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "46/100, Discriminator Loss: 1.2429213523864746, Generator Loss: [array(1.2516351, dtype=float32), array(1.2516351, dtype=float32), array(0.2652853, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "47/100, Discriminator Loss: 1.2559770345687866, Generator Loss: [array(1.2649776, dtype=float32), array(1.2649776, dtype=float32), array(0.2629654, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "48/100, Discriminator Loss: 1.2679803371429443, Generator Loss: [array(1.2765173, dtype=float32), array(1.2765173, dtype=float32), array(0.26236978, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "49/100, Discriminator Loss: 1.2790122032165527, Generator Loss: [array(1.2874225, dtype=float32), array(1.2874225, dtype=float32), array(0.26179847, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "50/100, Discriminator Loss: 1.290391445159912, Generator Loss: [array(1.2994081, dtype=float32), array(1.2994081, dtype=float32), array(0.2625, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "51/100, Discriminator Loss: 1.3022996187210083, Generator Loss: [array(1.3105415, dtype=float32), array(1.3105415, dtype=float32), array(0.2613358, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "52/100, Discriminator Loss: 1.3128753900527954, Generator Loss: [array(1.3212386, dtype=float32), array(1.3212386, dtype=float32), array(0.2611178, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "53/100, Discriminator Loss: 1.3241298198699951, Generator Loss: [array(1.3321524, dtype=float32), array(1.3321524, dtype=float32), array(0.25972876, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "54/100, Discriminator Loss: 1.3354933261871338, Generator Loss: [array(1.3439498, dtype=float32), array(1.3439498, dtype=float32), array(0.2578125, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "55/100, Discriminator Loss: 1.346189022064209, Generator Loss: [array(1.3545932, dtype=float32), array(1.3545932, dtype=float32), array(0.25823864, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "56/100, Discriminator Loss: 1.3572478294372559, Generator Loss: [array(1.3658836, dtype=float32), array(1.3658836, dtype=float32), array(0.2578125, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "57/100, Discriminator Loss: 1.3680349588394165, Generator Loss: [array(1.3758253, dtype=float32), array(1.3758253, dtype=float32), array(0.25740132, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "58/100, Discriminator Loss: 1.37754225730896, Generator Loss: [array(1.3848294, dtype=float32), array(1.3848294, dtype=float32), array(0.2572737, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "59/100, Discriminator Loss: 1.387254238128662, Generator Loss: [array(1.3951236, dtype=float32), array(1.3951236, dtype=float32), array(0.2571504, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "60/100, Discriminator Loss: 1.3974473476409912, Generator Loss: [array(1.4056135, dtype=float32), array(1.4056135, dtype=float32), array(0.2575521, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "61/100, Discriminator Loss: 1.408602237701416, Generator Loss: [array(1.4167892, dtype=float32), array(1.4167892, dtype=float32), array(0.25717214, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "62/100, Discriminator Loss: 1.4187085628509521, Generator Loss: [array(1.4260869, dtype=float32), array(1.4260869, dtype=float32), array(0.25655243, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "63/100, Discriminator Loss: 1.428324818611145, Generator Loss: [array(1.4357905, dtype=float32), array(1.4357905, dtype=float32), array(0.25570437, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "64/100, Discriminator Loss: 1.4375213384628296, Generator Loss: [array(1.4452022, dtype=float32), array(1.4452022, dtype=float32), array(0.25610352, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "65/100, Discriminator Loss: 1.4465084075927734, Generator Loss: [array(1.4534769, dtype=float32), array(1.4534769, dtype=float32), array(0.25649038, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "66/100, Discriminator Loss: 1.4557631015777588, Generator Loss: [array(1.4629104, dtype=float32), array(1.4629104, dtype=float32), array(0.25520834, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "67/100, Discriminator Loss: 1.4646186828613281, Generator Loss: [array(1.471825, dtype=float32), array(1.471825, dtype=float32), array(0.2548974, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "68/100, Discriminator Loss: 1.4740065336227417, Generator Loss: [array(1.4813691, dtype=float32), array(1.4813691, dtype=float32), array(0.25413603, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "69/100, Discriminator Loss: 1.4830962419509888, Generator Loss: [array(1.4904256, dtype=float32), array(1.4904256, dtype=float32), array(0.25384963, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "70/100, Discriminator Loss: 1.4917254447937012, Generator Loss: [array(1.4989961, dtype=float32), array(1.4989961, dtype=float32), array(0.2546875, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "71/100, Discriminator Loss: 1.50014066696167, Generator Loss: [array(1.5070117, dtype=float32), array(1.5070117, dtype=float32), array(0.25462148, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "72/100, Discriminator Loss: 1.5087997913360596, Generator Loss: [array(1.5157359, dtype=float32), array(1.5157359, dtype=float32), array(0.2543403, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "73/100, Discriminator Loss: 1.5173835754394531, Generator Loss: [array(1.5242138, dtype=float32), array(1.5242138, dtype=float32), array(0.2540668, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "74/100, Discriminator Loss: 1.526127576828003, Generator Loss: [array(1.5333161, dtype=float32), array(1.5333161, dtype=float32), array(0.2533784, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "75/100, Discriminator Loss: 1.5355761051177979, Generator Loss: [array(1.5427599, dtype=float32), array(1.5427599, dtype=float32), array(0.25270835, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "76/100, Discriminator Loss: 1.5441269874572754, Generator Loss: [array(1.5505114, dtype=float32), array(1.5505114, dtype=float32), array(0.25287828, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "77/100, Discriminator Loss: 1.5510101318359375, Generator Loss: [array(1.556774, dtype=float32), array(1.556774, dtype=float32), array(0.25223213, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "78/100, Discriminator Loss: 1.5577619075775146, Generator Loss: [array(1.5644548, dtype=float32), array(1.5644548, dtype=float32), array(0.25320512, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "79/100, Discriminator Loss: 1.5654571056365967, Generator Loss: [array(1.5718225, dtype=float32), array(1.5718225, dtype=float32), array(0.25336233, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "80/100, Discriminator Loss: 1.5735461711883545, Generator Loss: [array(1.5804672, dtype=float32), array(1.5804672, dtype=float32), array(0.2529297, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "81/100, Discriminator Loss: 1.5814073085784912, Generator Loss: [array(1.5876919, dtype=float32), array(1.5876919, dtype=float32), array(0.25308642, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "82/100, Discriminator Loss: 1.5886008739471436, Generator Loss: [array(1.5947963, dtype=float32), array(1.5947963, dtype=float32), array(0.2526677, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "83/100, Discriminator Loss: 1.596113681793213, Generator Loss: [array(1.6025839, dtype=float32), array(1.6025839, dtype=float32), array(0.25207078, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "84/100, Discriminator Loss: 1.6037126779556274, Generator Loss: [array(1.6099058, dtype=float32), array(1.6099058, dtype=float32), array(0.25204614, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "85/100, Discriminator Loss: 1.6110200881958008, Generator Loss: [array(1.6171702, dtype=float32), array(1.6171702, dtype=float32), array(0.25128677, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "86/100, Discriminator Loss: 1.617814064025879, Generator Loss: [array(1.6242542, dtype=float32), array(1.6242542, dtype=float32), array(0.25181687, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "87/100, Discriminator Loss: 1.6248705387115479, Generator Loss: [array(1.6310332, dtype=float32), array(1.6310332, dtype=float32), array(0.25215518, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "88/100, Discriminator Loss: 1.6318097114562988, Generator Loss: [array(1.6380258, dtype=float32), array(1.6380258, dtype=float32), array(0.25248578, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "89/100, Discriminator Loss: 1.6387510299682617, Generator Loss: [array(1.6447608, dtype=float32), array(1.6447608, dtype=float32), array(0.25263342, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "90/100, Discriminator Loss: 1.645683765411377, Generator Loss: [array(1.6517278, dtype=float32), array(1.6517278, dtype=float32), array(0.25260416, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "91/100, Discriminator Loss: 1.6528301239013672, Generator Loss: [array(1.6590645, dtype=float32), array(1.6590645, dtype=float32), array(0.25257555, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "92/100, Discriminator Loss: 1.6599531173706055, Generator Loss: [array(1.6658727, dtype=float32), array(1.6658727, dtype=float32), array(0.25203803, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "93/100, Discriminator Loss: 1.6665767431259155, Generator Loss: [array(1.6723994, dtype=float32), array(1.6723994, dtype=float32), array(0.25235215, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "94/100, Discriminator Loss: 1.6733722686767578, Generator Loss: [array(1.6794447, dtype=float32), array(1.6794447, dtype=float32), array(0.2521609, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "95/100, Discriminator Loss: 1.6798007488250732, Generator Loss: [array(1.6855832, dtype=float32), array(1.6855832, dtype=float32), array(0.25263157, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "96/100, Discriminator Loss: 1.686464548110962, Generator Loss: [array(1.6923832, dtype=float32), array(1.6923832, dtype=float32), array(0.25276694, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "97/100, Discriminator Loss: 1.693005084991455, Generator Loss: [array(1.6986516, dtype=float32), array(1.6986516, dtype=float32), array(0.25209406, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "98/100, Discriminator Loss: 1.6993670463562012, Generator Loss: [array(1.7048268, dtype=float32), array(1.7048268, dtype=float32), array(0.25175384, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "99/100, Discriminator Loss: 1.7050859928131104, Generator Loss: [array(1.7106943, dtype=float32), array(1.7106943, dtype=float32), array(0.25205177, dtype=float32)]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "100/100, Discriminator Loss: 1.7118144035339355, Generator Loss: [array(1.7175554, dtype=float32), array(1.7175554, dtype=float32), array(0.25109375, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "data = load_data()\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator()\n",
    "gan = compile_gan(generator, discriminator)\n",
    "\n",
    "train_gan(generator, discriminator, gan, data, epochs, batch_size, latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596de80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
